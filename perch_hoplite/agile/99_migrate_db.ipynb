{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Migrate db from `perch-hoplite < 1.0`\n",
        "\n",
        "If you've previously used `perch-hoplite < 1.0` to create a database, use this notebook to convert it to `perch-hoplite == 1.*`."
      ],
      "metadata": {
        "id": "3-EWV2-tVGAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Imports\n",
        "\n",
        "import json\n",
        "import shutil\n",
        "import sqlite3\n",
        "from typing import Any\n",
        "\n",
        "from etils import epath\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from ml_collections import config_dict\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "from perch_hoplite.db import interface\n",
        "from perch_hoplite.db import sqlite_usearch_impl"
      ],
      "metadata": {
        "id": "qJvQpaShWFtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inputs and outputs {vertical-output: true}\n",
        "\n",
        "# @markdown Input db location:\n",
        "input_db_path = \"\"  # @param {type: \"string\"}\n",
        "input_db_path = epath.Path(input_db_path)\n",
        "\n",
        "# @markdown Output db location:\n",
        "output_db_path = \"\"  # @param {type: \"string\"}\n",
        "output_db_path = epath.Path(output_db_path)\n",
        "\n",
        "# @markdown Window size (in seconds) used by the embeddings model.\n",
        "# @markdown Needed to compute the end offset because the old database stored only the start offset.\n",
        "window_size_s = 5.0  # @param {type: \"number\"}"
      ],
      "metadata": {
        "id": "eYl9wLW8Wxvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Delete old db migration {vertical-output: true}\n",
        "\n",
        "if output_db_path.exists():\n",
        "  # Ask the user to confirm if they want to delete the old output directory.\n",
        "\n",
        "  # 1. Setup the widgets.\n",
        "  label = widgets.HTML(value=f\"Output directory already exists: <b>{output_db_path}</b>\")\n",
        "  btn_delete = widgets.Button(description=\"Delete Directory\", button_style=\"warning\", icon=\"trash\")\n",
        "  btn_confirm = widgets.Button(description=\"Yes\", button_style=\"danger\", layout={\"display\": \"none\"})\n",
        "  btn_cancel = widgets.Button(description=\"Cancel\", layout={\"display\": \"none\"})\n",
        "  output = widgets.Output()\n",
        "\n",
        "  # 2. Define the logic.\n",
        "  def show_confirmation(b):\n",
        "      btn_delete.layout.display = \"none\"\n",
        "      btn_confirm.layout.display = \"inline-block\"\n",
        "      btn_cancel.layout.display = \"inline-block\"\n",
        "      with output:\n",
        "          output.clear_output()\n",
        "          print(\"⚠️ Are you sure? This cannot be undone.\")\n",
        "\n",
        "  def cancel_action(b):\n",
        "      btn_delete.layout.display = \"inline-block\"\n",
        "      btn_confirm.layout.display = \"none\"\n",
        "      btn_cancel.layout.display = \"none\"\n",
        "      with output:\n",
        "          output.clear_output()\n",
        "\n",
        "  def perform_deletion(b):\n",
        "      with output:\n",
        "          output.clear_output()\n",
        "          try:\n",
        "              shutil.rmtree(output_db_path)\n",
        "              print(f\"✅ Successfully deleted: {output_db_path}\")\n",
        "              btn_confirm.disabled = True\n",
        "              btn_cancel.description = \"Done\"\n",
        "          except Exception as e:\n",
        "              print(f\"❌ Error: {e}\")\n",
        "\n",
        "  # 3. Wire up the buttons.\n",
        "  btn_delete.on_click(show_confirmation)\n",
        "  btn_cancel.on_click(cancel_action)\n",
        "  btn_confirm.on_click(perform_deletion)\n",
        "\n",
        "  # 4. Display the UI.\n",
        "  controls = widgets.HBox([btn_delete, btn_confirm, btn_cancel])\n",
        "  display(widgets.VBox([label, controls, output]))\n",
        "\n",
        "else:\n",
        "\n",
        "  label = widgets.HTML(value=f\"Output directory doesn't exist yet: <b>{output_db_path}</b>\")\n",
        "  display(label)"
      ],
      "metadata": {
        "id": "lDgiuwhEeyhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convert the SQLite database\n",
        "\n",
        "# Define helper function.\n",
        "def deserialize_array(serialized: bytes, dtype: type[Any]) -> np.ndarray:\n",
        "  return np.frombuffer(serialized, dtype=np.dtype(dtype).newbyteorder('<'))\n",
        "\n",
        "# Check the input database to make sure it's in the old format.\n",
        "old_db = sqlite3.connect(input_db_path / \"hoplite.sqlite\")\n",
        "old_cursor = old_db.cursor()\n",
        "old_cursor.execute(\"\"\"\n",
        "  SELECT name\n",
        "  FROM sqlite_master\n",
        "  WHERE type = \"table\"\n",
        "\"\"\")\n",
        "old_tables = {row[0] for row in old_cursor.fetchall()}\n",
        "expected_old_tables = {\"hoplite_metadata\", \"hoplite_sources\", \"hoplite_embeddings\", \"hoplite_labels\"}\n",
        "assert len(old_tables & expected_old_tables) == 4, \"Something is wrong with the old database. Please check its tables.\"\n",
        "\n",
        "# Load the usearch_cfg.\n",
        "old_cursor.execute(\"\"\"\n",
        "  SELECT data\n",
        "  FROM hoplite_metadata\n",
        "  WHERE key = \"usearch_config\"\n",
        "\"\"\")\n",
        "usearch_cfg = config_dict.ConfigDict(json.loads(old_cursor.fetchone()[0]))\n",
        "\n",
        "# Create the new database.\n",
        "new_db = sqlite_usearch_impl.SQLiteUSearchDB.create(output_db_path, usearch_cfg)\n",
        "\n",
        "# Copy the hoplite metadata.\n",
        "old_cursor.execute(\"\"\"\n",
        "  SELECT key, data\n",
        "  FROM hoplite_metadata\n",
        "  WHERE key != \"usearch_config\"\n",
        "\"\"\")\n",
        "for row in old_cursor.fetchall():\n",
        "  key = row[0]\n",
        "  value = config_dict.ConfigDict(json.loads(row[1]))\n",
        "  new_db.insert_metadata(key, value)\n",
        "new_db.commit()\n",
        "\n",
        "print(\"Copying old sources into new deployments and recordings...\")\n",
        "old_dataset_to_new_deployment_id = {}\n",
        "old_source_id_to_new_recording_id = {}\n",
        "old_cursor.execute(\"\"\"\n",
        "  SELECT DISTINCT dataset\n",
        "  FROM hoplite_sources\n",
        "\"\"\")\n",
        "for dataset, in tqdm.tqdm(old_cursor.fetchall()):\n",
        "  old_dataset_to_new_deployment_id[dataset] = new_db.insert_deployment(\n",
        "      name=dataset,\n",
        "      project=dataset,\n",
        "  )\n",
        "old_cursor.execute(\"\"\"\n",
        "  SELECT id, dataset, source\n",
        "  FROM hoplite_sources\n",
        "\"\"\")\n",
        "for source_id, dataset, source in tqdm.tqdm(old_cursor.fetchall()):\n",
        "  old_source_id_to_new_recording_id[source_id] = new_db.insert_recording(\n",
        "      filename=source,\n",
        "      deployment_id=old_dataset_to_new_deployment_id[dataset],\n",
        "  )\n",
        "new_db.commit()\n",
        "\n",
        "print(\"Creating windows...\")\n",
        "# Copy the old embeddings into new windows. Do not reinsert the embedding vector into USearch since\n",
        "# we're reusing the vector search index as it is. The trick for obtaining the same window ids is to\n",
        "# insert windows in the original order and remove gaps.\n",
        "old_cursor.execute(\"\"\"\n",
        "  SELECT id, source_idx, offsets\n",
        "  FROM hoplite_embeddings\n",
        "  ORDER BY id\n",
        "\"\"\")\n",
        "last_window_id = 0\n",
        "\n",
        "for embedding_id, source_id, old_offsets in tqdm.tqdm(old_cursor.fetchall()):\n",
        "  while last_window_id + 1 < embedding_id:\n",
        "    dummy_window_id = new_db.insert_window(\n",
        "        recording_id=1,\n",
        "        offsets=[],\n",
        "        embedding=None,\n",
        "    )\n",
        "    new_db.remove_window(dummy_window_id)\n",
        "    last_window_id += 1\n",
        "\n",
        "  # The old database stored only the start offset. Use the provided `window_size_s` to compute the\n",
        "  # end offset.\n",
        "  start_offset = deserialize_array(old_offsets, np.float32)[0].item()\n",
        "  end_offset = start_offset + window_size_s\n",
        "  window_id = new_db.insert_window(\n",
        "      recording_id=old_source_id_to_new_recording_id[source_id],\n",
        "      offsets=[start_offset, end_offset],\n",
        "      embedding=None,\n",
        "  )\n",
        "  assert window_id == embedding_id\n",
        "\n",
        "  last_window_id += 1\n",
        "\n",
        "new_db.commit()\n",
        "\n",
        "# Map window_id to new (recording_id, offsets) tuples, to be used for mapping annotations in the\n",
        "# new table schema.\n",
        "recording_offsets = {\n",
        "    window.id : (window.recording_id, window.offsets)\n",
        "    for window in new_db.get_all_windows()\n",
        "}\n",
        "\n",
        "# Copy the old labels into new annotations. No need to map the window ids since they remain the same.\n",
        "old_cursor.execute(\"\"\"\n",
        "  SELECT embedding_id, label, type, provenance\n",
        "  FROM hoplite_labels\n",
        "\"\"\")\n",
        "for old_embedding_id, old_label, old_type, old_provenance in tqdm.tqdm(old_cursor.fetchall()):\n",
        "  new_db.insert_annotation(\n",
        "      recording_id=recording_offsets[old_embedding_id][0],\n",
        "      offsets=recording_offsets[old_embedding_id][1],\n",
        "      label=old_label,\n",
        "      label_type=interface.LabelType(old_type),\n",
        "      provenance=old_provenance,\n",
        "  )\n",
        "new_db.commit()"
      ],
      "metadata": {
        "id": "lyZceE5LuCm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inspect and close Hoplite db {vertical-output: true}\n",
        "\n",
        "print(\"Deployments:\", len(new_db.get_all_deployments()))\n",
        "print(\"Recordings:\", len(new_db.get_all_recordings()))\n",
        "print(\"Windows:\", len(new_db.get_all_windows()))\n",
        "print(\"Annotations:\", len(new_db.get_all_annotations()))\n",
        "print(\"Embeddings:\", new_db.count_embeddings())\n",
        "\n",
        "del new_db"
      ],
      "metadata": {
        "id": "LhGAHe5vQ8bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copy the vector search index {vertical-output: true}\n",
        "\n",
        "output_index_path = (input_db_path / \"usearch.index\").copy(\n",
        "    output_db_path / \"usearch.index\",\n",
        "    overwrite=True,\n",
        ")\n",
        "print(\"Output index:\", output_index_path)"
      ],
      "metadata": {
        "id": "r2DUOsH1rde4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Reload and reinspect Hoplite db {vertical-output: true}\n",
        "\n",
        "new_db = sqlite_usearch_impl.SQLiteUSearchDB.create(output_db_path, usearch_cfg)\n",
        "\n",
        "print(\"Deployments:\", len(new_db.get_all_deployments()))\n",
        "print(\"Recordings:\", len(new_db.get_all_recordings()))\n",
        "print(\"Windows:\", len(new_db.get_all_windows()))\n",
        "print(\"Annotations:\", len(new_db.get_all_annotations()))\n",
        "print(\"Embeddings:\", new_db.count_embeddings())"
      ],
      "metadata": {
        "id": "M2JMTGYOP_qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inspect old SQLite database for final comparison {vertical-output: true}\n",
        "\n",
        "num_datasets = old_cursor.execute(\"\"\"\n",
        "  SELECT COUNT(DISTINCT dataset)\n",
        "  FROM hoplite_sources\n",
        "\"\"\").fetchone()[0]\n",
        "num_sources = old_cursor.execute(\"\"\"\n",
        "  SELECT COUNT(*)\n",
        "  FROM hoplite_sources\n",
        "\"\"\").fetchone()[0]\n",
        "num_embeddings = old_cursor.execute(\"\"\"\n",
        "  SELECT COUNT(*)\n",
        "  FROM hoplite_embeddings\n",
        "\"\"\").fetchone()[0]\n",
        "num_labels = old_cursor.execute(\"\"\"\n",
        "  SELECT COUNT(*)\n",
        "  FROM hoplite_labels\n",
        "\"\"\").fetchone()[0]\n",
        "\n",
        "print(\"Datasets:\", num_datasets)\n",
        "print(\"Sources:\", num_sources)\n",
        "print(\"Embeddings:\", num_embeddings)\n",
        "print(\"Labels:\", num_labels)"
      ],
      "metadata": {
        "id": "6JyvI8ew8TDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "last_runtime": {
        "build_target": "//third_party/py/chirp:colab_binary",
        "kind": "private"
      }
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
